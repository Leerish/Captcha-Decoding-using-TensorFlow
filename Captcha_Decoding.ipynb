{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxYwhTIigpgDakI2RLnH5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leerish/Captcha-Decoding-using-TensorFlow/blob/main/Captcha_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Captcha to Text OCR using TensorFlow\n",
        "\n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "**Captcha (Completely Automated Public Turing test to tell Computers and Humans Apart)** is a challenge-response test used in computing to determine whether or not the user is human. It typically involves presenting the user with a distorted image of text, and the user must correctly transcribe the text to prove they are human. Captchas are commonly used in online forms, website sign-ups, and account logins to prevent automated bots from abusing or spamming the system.\n",
        "\n",
        "\n",
        "The model is designed to read and interpret captcha images using TensorFlow. It utilizes deep learning techniques, particularly convolutional neural networks (CNNs), to recognize the distorted text within captcha images. By training on a dataset of labeled captcha images, the model learns to extract features and classify the characters present in the images. Once trained, the model can then be used to predict the text present in unseen captcha images.\n",
        "\n",
        "Key components of the captcha reading model may include:\n",
        "\n",
        "1. **Data Preprocessing**: Captcha images are preprocessed to enhance their quality and make them suitable for training. Preprocessing steps may include resizing, normalization, noise reduction, and augmentation.\n",
        "\n",
        "2. **Model Architecture**: The model architecture defines the structure of the neural network used for captcha recognition. It typically consists of multiple layers, including convolutional layers for feature extraction, pooling layers for downsampling, and fully connected layers for classification.\n",
        "\n",
        "3. **Training**: The model is trained on a dataset of labeled captcha images. During training, the model learns to minimize the difference between its predictions and the ground truth labels using optimization algorithms like stochastic gradient descent (SGD) or Adam.\n",
        "\n",
        "4. **Evaluation**: The trained model is evaluated on a separate validation dataset to assess its performance. Evaluation metrics such as accuracy, precision, recall, and F1 score are used to measure the model's effectiveness in captcha recognition.\n",
        "\n",
        "5. **Deployment**: Once trained and evaluated, the model can be deployed in production environments to read captcha images in real-time. This may involve integrating the model into web applications, APIs, or other systems where captcha verification is required.\n",
        "\n",
        "Overall, the captcha reading model using TensorFlow demonstrates the application of deep learning techniques in solving practical challenges related to computer vision and security. It provides an automated solution for reading and interpreting captcha images, contributing to improved user experience and security in online applications."
      ],
      "metadata": {
        "id": "lIv_69Ot2zG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFAvGpn-gT_6",
        "outputId": "64a7d275-3ef6-48f2-dc7e-fc77dd86049e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-17 14:50:40--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-17 14:50:40 (20.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting up initial Configurations"
      ],
      "metadata": {
        "id": "AbwIzYyxGs3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from mltu.configs import BaseModelConfigs\n",
        "\n",
        "\n",
        "class ModelConfigs(BaseModelConfigs):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model_path = os.path.join(\"Models/02_captcha_to_text\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
        "        self.vocab = \"\"\n",
        "        self.height = 50\n",
        "        self.width = 200\n",
        "        self.max_text_length = 0\n",
        "        self.batch_size = 64\n",
        "        self.learning_rate = 1e-3\n",
        "        self.train_epochs = 70\n",
        "        self.train_workers = 20"
      ],
      "metadata": {
        "id": "m4K7q2PAlyqs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "O7wsFNxcGuoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install stow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sNEje37n1tT",
        "outputId": "9016d48c-080a-4243-9b96-8607f5895615"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stow\n",
            "  Downloading stow-1.3.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stow) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from stow) (4.11.0)\n",
            "Installing collected packages: stow\n",
            "Successfully installed stow-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mltu==0.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CfoYxwIpAmf",
        "outputId": "24ae786a-a4a8-4394-9132-e1b1bce3a729"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mltu==0.1.4 in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: stow>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (4.66.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (4.8.0.76)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (1.14.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (1.17.3)\n",
            "Requirement already satisfied: tensorflow<=2.10.1 in /usr/local/lib/python3.10/dist-packages (from mltu==0.1.4) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from stow>=1.1.6->mltu==0.1.4) (4.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (2.0.7)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.62.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (3.9.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (24.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (0.36.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10.1->mltu==0.1.4) (1.14.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->mltu==0.1.4) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->mltu==0.1.4) (1.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->mltu==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mltu==0.1.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mltu==0.1.4) (2024.1)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx->mltu==0.1.4) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx->mltu==0.1.4) (2.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.10.1->mltu==0.1.4) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx->mltu==0.1.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx->mltu==0.1.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx->mltu==0.1.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx->mltu==0.1.4) (2024.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->mltu==0.1.4) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->mltu==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10.1->mltu==0.1.4) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocesing"
      ],
      "metadata": {
        "id": "F1TncjSIGyo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stow\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download_and_unzip(url, extract_to='Datasets'):\n",
        "    http_response = urlopen(url)\n",
        "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "    zipfile.extractall(path=extract_to)\n",
        "\n",
        "if not stow.exists(stow.join('Datasets', 'captcha_images_v2')):\n",
        "    download_and_unzip('https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip', extract_to='Datasets')"
      ],
      "metadata": {
        "id": "J5Lb6R8Yq2Hx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, vocab, max_len = [], set(), 0\n",
        "captcha_path = os.path.join(\"Datasets\", \"captcha_images_v2\")\n",
        "for file in os.listdir(captcha_path):\n",
        "    file_path = os.path.join(captcha_path, file)\n",
        "    label = os.path.splitext(file)[0] # Get the file name without the extension\n",
        "    dataset.append([file_path, label])\n",
        "    vocab.update(list(label))\n",
        "    max_len = max(max_len, len(label))\n",
        "\n",
        "configs = ModelConfigs()\n",
        "\n",
        "# Save vocab and maximum text length to configs\n",
        "configs.vocab = \"\".join(vocab)\n",
        "configs.max_text_length = max_len\n",
        "configs.save()"
      ],
      "metadata": {
        "id": "rI58tiporfec"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "\n",
        "from mltu.dataProvider import DataProvider\n",
        "from mltu.losses import CTCloss\n",
        "from mltu.callbacks import Model2onnx, TrainLogger\n",
        "from mltu.metrics import CWERMetric\n",
        "\n",
        "from mltu.preprocessors import ImageReader\n",
        "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
        "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate\n",
        "\n",
        "from model import train_model\n",
        "from configs import ModelConfigs\n",
        "\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n"
      ],
      "metadata": {
        "id": "7Qykhh8es13m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mltu.dataProvider import DataProvider\n",
        "from mltu.preprocessors import ImageReader\n",
        "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
        "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate\n",
        "\n",
        "data_provider = DataProvider(\n",
        "    dataset=dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[ImageReader()],\n",
        "    transformers=[\n",
        "        ImageResizer(configs.width, configs.height),\n",
        "        LabelIndexer(configs.vocab),\n",
        "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
        "        ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCDeV3Gbs_WG",
        "outputId": "dd769033-6fc9-491f-b81f-d29b65505d91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:mltu.dataProvider:Skipping Dataset validation...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_provider, val_data_provider = data_provider.split(split = 0.9)"
      ],
      "metadata": {
        "id": "wV0iUzWbuAHt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_provider.augmentors = [RandomBrightness(), RandomRotate(), RandomErodeDilate()]"
      ],
      "metadata": {
        "id": "1ThdB10NuCUp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model\n"
      ],
      "metadata": {
        "id": "jQzMFntOG35W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(\n",
        "    input_dim = (configs.height, configs.width, 3),\n",
        "    output_dim = len(configs.vocab),\n",
        ")"
      ],
      "metadata": {
        "id": "ldvf94IWuEz3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate),\n",
        "    loss=CTCloss(),\n",
        "    metrics=[CWERMetric()],\n",
        ")"
      ],
      "metadata": {
        "id": "u4WFj1wquH9X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "earlystopper = EarlyStopping(monitor='val_CER', patience=40, verbose=1)\n",
        "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor='val_CER', verbose=1, save_best_only=True, mode='min')\n",
        "trainLogger = TrainLogger(configs.model_path)\n",
        "tb_callback = TensorBoard(f'{configs.model_path}/logs', update_freq=1)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_CER', factor=0.9, min_delta=1e-10, patience=20, verbose=1, mode='auto')\n",
        "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")"
      ],
      "metadata": {
        "id": "SFYOU_8guOMR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_data_provider,\n",
        "    validation_data=val_data_provider,\n",
        "    epochs=70,\n",
        "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
        "    workers=configs.train_workers\n",
        ")\n",
        "\n",
        "# Save training and validation datasets as csv files\n",
        "train_data_provider.to_csv(stow.join(configs.model_path, 'train.csv'))\n",
        "val_data_provider.to_csv(stow.join(configs.model_path, 'val.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfBj_JfTuQev",
        "outputId": "e0d69afb-9009-4ef9-fead-87db8daeeb95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3212 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 1: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 0; loss: 16.321199417114258; CER: 1.0; WER: 1.0; val_loss: 16.35167121887207; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.3212 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3517 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 2/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3149 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 2: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 1; loss: 16.31488609313965; CER: 1.0; WER: 1.0; val_loss: 16.328990936279297; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.3149 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3290 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 3/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3159 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 3: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 2; loss: 16.315914154052734; CER: 1.0; WER: 1.0; val_loss: 16.349382400512695; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.3159 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3494 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 4/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2888 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 4: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 3; loss: 16.28876304626465; CER: 1.0; WER: 1.0; val_loss: 16.31635856628418; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 127s 9s/step - loss: 16.2888 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3164 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 5/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2987 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 5: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 4; loss: 16.29865074157715; CER: 1.0; WER: 1.0; val_loss: 16.32975196838379; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.2987 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3298 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 6/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2802 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 6: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 5; loss: 16.280241012573242; CER: 1.0; WER: 1.0; val_loss: 16.33698081970215; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.2802 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3370 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 7/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2376 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 7: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 6; loss: 16.23756217956543; CER: 1.0; WER: 1.0; val_loss: 16.319162368774414; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 49s 3s/step - loss: 16.2376 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3192 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 8/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.1851 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 8: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 7; loss: 16.18514060974121; CER: 1.0; WER: 1.0; val_loss: 16.334077835083008; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.1851 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3341 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 9/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.0762 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 9: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 8; loss: 16.07619285583496; CER: 1.0; WER: 1.0; val_loss: 16.247892379760742; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 16.0762 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2479 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 10/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.8853 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 10: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 9; loss: 15.885340690612793; CER: 1.0; WER: 1.0; val_loss: 16.239238739013672; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 15.8853 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2392 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 11/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.5978 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 11: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 10; loss: 15.597818374633789; CER: 1.0; WER: 1.0; val_loss: 16.165714263916016; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 47s 3s/step - loss: 15.5978 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.1657 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 12/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.1773 - CER: 0.9997 - WER: 1.0000\n",
            "Epoch 12: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 11; loss: 15.177270889282227; CER: 0.9982905387878418; WER: 1.0; val_loss: 15.894679069519043; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 15.1773 - CER: 0.9996 - WER: 1.0000 - val_loss: 15.8947 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 13/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.7224 - CER: 0.9945 - WER: 1.0000\n",
            "Epoch 13: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 12; loss: 14.722421646118164; CER: 0.9931623935699463; WER: 1.0; val_loss: 14.561226844787598; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 47s 3s/step - loss: 14.7224 - CER: 0.9944 - WER: 1.0000 - val_loss: 14.5612 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 14/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.1183 - CER: 0.9709 - WER: 1.0000\n",
            "Epoch 14: val_CER improved from 1.00000 to 0.95000, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 13; loss: 14.11832332611084; CER: 0.9589743614196777; WER: 1.0; val_loss: 14.462864875793457; val_CER: 0.9500000476837158; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 46s 3s/step - loss: 14.1183 - CER: 0.9702 - WER: 1.0000 - val_loss: 14.4629 - val_CER: 0.9500 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 15/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 13.4373 - CER: 0.9187 - WER: 1.0000\n",
            "Epoch 15: val_CER improved from 0.95000 to 0.92500, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 14; loss: 13.437328338623047; CER: 0.8993590474128723; WER: 1.0; val_loss: 17.25698471069336; val_CER: 0.9249999523162842; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 13.4373 - CER: 0.9175 - WER: 1.0000 - val_loss: 17.2570 - val_CER: 0.9250 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 16/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.7863 - CER: 0.8573 - WER: 1.0000\n",
            "Epoch 16: val_CER did not improve from 0.92500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 15; loss: 12.786291122436523; CER: 0.8497862815856934; WER: 1.0; val_loss: 19.582263946533203; val_CER: 0.9249999523162842; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 48s 3s/step - loss: 12.7863 - CER: 0.8568 - WER: 1.0000 - val_loss: 19.5823 - val_CER: 0.9250 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 17/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 11.9811 - CER: 0.8048 - WER: 1.0000\n",
            "Epoch 17: val_CER improved from 0.92500 to 0.91538, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 16; loss: 11.98105239868164; CER: 0.7886751890182495; WER: 1.0; val_loss: 21.24038314819336; val_CER: 0.9153845906257629; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 53s 4s/step - loss: 11.9811 - CER: 0.8038 - WER: 1.0000 - val_loss: 21.2404 - val_CER: 0.9154 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 18/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 11.2979 - CER: 0.7680 - WER: 1.0000\n",
            "Epoch 18: val_CER did not improve from 0.91538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 17; loss: 11.297892570495605; CER: 0.7566239237785339; WER: 1.0; val_loss: 23.39720916748047; val_CER: 0.9307692646980286; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 46s 3s/step - loss: 11.2979 - CER: 0.7672 - WER: 1.0000 - val_loss: 23.3972 - val_CER: 0.9308 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 19/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.6740 - CER: 0.7073 - WER: 1.0000\n",
            "Epoch 19: val_CER improved from 0.91538 to 0.91346, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 18; loss: 10.674028396606445; CER: 0.7119658589363098; WER: 1.0; val_loss: 21.676023483276367; val_CER: 0.9134615659713745; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 47s 3s/step - loss: 10.6740 - CER: 0.7076 - WER: 1.0000 - val_loss: 21.6760 - val_CER: 0.9135 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 20/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.0406 - CER: 0.6634 - WER: 0.9995\n",
            "Epoch 20: val_CER improved from 0.91346 to 0.83269, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 19; loss: 10.04058837890625; CER: 0.6645299792289734; WER: 0.9989316463470459; val_loss: 15.628806114196777; val_CER: 0.8326922655105591; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 47s 3s/step - loss: 10.0406 - CER: 0.6635 - WER: 0.9994 - val_loss: 15.6288 - val_CER: 0.8327 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 21/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 9.4271 - CER: 0.6326 - WER: 0.9947\n",
            "Epoch 21: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 20; loss: 9.427144050598145; CER: 0.6185897588729858; WER: 0.995726466178894; val_loss: 32.5456657409668; val_CER: 0.9442307353019714; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 46s 3s/step - loss: 9.4271 - CER: 0.6317 - WER: 0.9947 - val_loss: 32.5457 - val_CER: 0.9442 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 22/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.8411 - CER: 0.5950 - WER: 0.9959\n",
            "Epoch 22: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 21; loss: 8.841062545776367; CER: 0.5829060077667236; WER: 0.995726466178894; val_loss: 31.69342613220215; val_CER: 0.9403846263885498; val_WER: 1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 46s 3s/step - loss: 8.8411 - CER: 0.5942 - WER: 0.9959 - val_loss: 31.6934 - val_CER: 0.9404 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 23/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.2190 - CER: 0.5545 - WER: 0.9901\n",
            "Epoch 23: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Epoch 22; loss: 8.218981742858887; CER: 0.547435998916626; WER: 0.9903846383094788; val_loss: 31.902193069458008; val_CER: 0.9307692646980286; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 47s 3s/step - loss: 8.2190 - CER: 0.5541 - WER: 0.9901 - val_loss: 31.9022 - val_CER: 0.9308 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 24/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.6860 - CER: 0.4955 - WER: 0.9831\n",
            "Epoch 24: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 23; loss: 7.686049461364746; CER: 0.49871793389320374; WER: 0.9775640964508057; val_loss: 33.69876480102539; val_CER: 0.934615433216095; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 7.6860 - CER: 0.4957 - WER: 0.9828 - val_loss: 33.6988 - val_CER: 0.9346 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 25/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.1089 - CER: 0.4639 - WER: 0.9560\n",
            "Epoch 25: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 24; loss: 7.1088714599609375; CER: 0.45876067876815796; WER: 0.9540598392486572; val_loss: 36.56772994995117; val_CER: 0.9480769634246826; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 7.1089 - CER: 0.4636 - WER: 0.9559 - val_loss: 36.5677 - val_CER: 0.9481 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 26/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.5665 - CER: 0.4239 - WER: 0.9409\n",
            "Epoch 26: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 25; loss: 6.566474437713623; CER: 0.4239315986633301; WER: 0.9412392973899841; val_loss: 36.87615203857422; val_CER: 0.934615433216095; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 6.5665 - CER: 0.4239 - WER: 0.9410 - val_loss: 36.8762 - val_CER: 0.9346 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 27/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.9744 - CER: 0.3809 - WER: 0.9367\n",
            "Epoch 27: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 26; loss: 5.9743733406066895; CER: 0.3790598213672638; WER: 0.9209401607513428; val_loss: 40.6323356628418; val_CER: 0.9480769038200378; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 5.9744 - CER: 0.3807 - WER: 0.9357 - val_loss: 40.6323 - val_CER: 0.9481 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 28/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.4887 - CER: 0.3509 - WER: 0.9049\n",
            "Epoch 28: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 27; loss: 5.488729476928711; CER: 0.34294870495796204; WER: 0.8846153616905212; val_loss: 38.77775955200195; val_CER: 0.9615384340286255; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 5.4887 - CER: 0.3504 - WER: 0.9036 - val_loss: 38.7778 - val_CER: 0.9615 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 29/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.0388 - CER: 0.3231 - WER: 0.8519\n",
            "Epoch 29: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 28; loss: 5.038846492767334; CER: 0.3053418695926666; WER: 0.8344017267227173; val_loss: 40.12788391113281; val_CER: 0.9865384697914124; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 5.0388 - CER: 0.3220 - WER: 0.8508 - val_loss: 40.1279 - val_CER: 0.9865 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 30/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.6476 - CER: 0.2892 - WER: 0.8176\n",
            "Epoch 30: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 29; loss: 4.647592544555664; CER: 0.28803423047065735; WER: 0.8301281929016113; val_loss: 37.050785064697266; val_CER: 0.9461538791656494; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 4.6476 - CER: 0.2891 - WER: 0.8183 - val_loss: 37.0508 - val_CER: 0.9462 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 31/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.2706 - CER: 0.2630 - WER: 0.7817\n",
            "Epoch 31: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 30; loss: 4.27063512802124; CER: 0.2587606906890869; WER: 0.7873931527137756; val_loss: 40.24337387084961; val_CER: 0.9711538553237915; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 4.2706 - CER: 0.2627 - WER: 0.7820 - val_loss: 40.2434 - val_CER: 0.9712 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 32/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.9439 - CER: 0.2491 - WER: 0.7837\n",
            "Epoch 32: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 31; loss: 3.943861484527588; CER: 0.2410256266593933; WER: 0.754273533821106; val_loss: 40.43387222290039; val_CER: 0.942307710647583; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 3.9439 - CER: 0.2486 - WER: 0.7819 - val_loss: 40.4339 - val_CER: 0.9423 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 33/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.5873 - CER: 0.2235 - WER: 0.7143\n",
            "Epoch 33: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 32; loss: 3.5873095989227295; CER: 0.21645300090312958; WER: 0.7190170884132385; val_loss: 42.04409408569336; val_CER: 0.9576922655105591; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 3.5873 - CER: 0.2230 - WER: 0.7146 - val_loss: 42.0441 - val_CER: 0.9577 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 34/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.3991 - CER: 0.2036 - WER: 0.6923\n",
            "Epoch 34: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 33; loss: 3.39909029006958; CER: 0.20213676989078522; WER: 0.688034176826477; val_loss: 41.32634353637695; val_CER: 0.9673077464103699; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 3.3991 - CER: 0.2035 - WER: 0.6920 - val_loss: 41.3263 - val_CER: 0.9673 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 35/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1768 - CER: 0.1925 - WER: 0.6368\n",
            "Epoch 35: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 34; loss: 3.1768181324005127; CER: 0.18888887763023376; WER: 0.6399572491645813; val_loss: 32.19667434692383; val_CER: 0.9711538553237915; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 3.1768 - CER: 0.1923 - WER: 0.6370 - val_loss: 32.1967 - val_CER: 0.9712 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 36/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.9089 - CER: 0.1854 - WER: 0.6654\n",
            "Epoch 36: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 35; loss: 2.9088709354400635; CER: 0.1754273623228073; WER: 0.627136766910553; val_loss: 35.311038970947266; val_CER: 1.076923131942749; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 2.9089 - CER: 0.1848 - WER: 0.6630 - val_loss: 35.3110 - val_CER: 1.0769 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 37/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.7006 - CER: 0.1523 - WER: 0.5593\n",
            "Epoch 37: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 36; loss: 2.7005527019500732; CER: 0.1536324918270111; WER: 0.5758547186851501; val_loss: 35.173500061035156; val_CER: 0.9615384340286255; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 2.7006 - CER: 0.1524 - WER: 0.5603 - val_loss: 35.1735 - val_CER: 0.9615 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 38/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.5366 - CER: 0.1435 - WER: 0.5353\n",
            "Epoch 38: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 37; loss: 2.53662371635437; CER: 0.14829060435295105; WER: 0.5512820482254028; val_loss: 25.88795280456543; val_CER: 0.876923143863678; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 2.5366 - CER: 0.1438 - WER: 0.5363 - val_loss: 25.8880 - val_CER: 0.8769 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 39/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.3276 - CER: 0.1383 - WER: 0.5146\n",
            "Epoch 39: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 38; loss: 2.3276312351226807; CER: 0.14017093181610107; WER: 0.5213675498962402; val_loss: 38.813804626464844; val_CER: 1.0211539268493652; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 2.3276 - CER: 0.1384 - WER: 0.5150 - val_loss: 38.8138 - val_CER: 1.0212 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 40/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1103 - CER: 0.1171 - WER: 0.4679\n",
            "Epoch 40: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 39; loss: 2.1103103160858154; CER: 0.1220085620880127; WER: 0.4839743673801422; val_loss: 35.80543899536133; val_CER: 1.0692307949066162; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "15/15 [==============================] - 45s 3s/step - loss: 2.1103 - CER: 0.1174 - WER: 0.4689 - val_loss: 35.8054 - val_CER: 1.0692 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 41/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.0187 - CER: 0.1091 - WER: 0.4368\n",
            "Epoch 41: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 40; loss: 2.0186805725097656; CER: 0.11880341917276382; WER: 0.46581196784973145; val_loss: 20.97980499267578; val_CER: 0.8423076868057251; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 2.0187 - CER: 0.1097 - WER: 0.4386 - val_loss: 20.9798 - val_CER: 0.8423 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 42/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.9681 - CER: 0.1074 - WER: 0.4383\n",
            "Epoch 42: val_CER did not improve from 0.83269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 41; loss: 1.968104362487793; CER: 0.11217950284481049; WER: 0.45085468888282776; val_loss: 22.076566696166992; val_CER: 0.857692301273346; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 1.9681 - CER: 0.1077 - WER: 0.4391 - val_loss: 22.0766 - val_CER: 0.8577 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 43/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.8036 - CER: 0.0997 - WER: 0.3992\n",
            "Epoch 43: val_CER improved from 0.83269 to 0.83077, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 42; loss: 1.8035746812820435; CER: 0.09615384787321091; WER: 0.3878205120563507; val_loss: 19.839141845703125; val_CER: 0.8307692408561707; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 1.8036 - CER: 0.0995 - WER: 0.3985 - val_loss: 19.8391 - val_CER: 0.8308 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 44/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.7036 - CER: 0.1016 - WER: 0.4157\n",
            "Epoch 44: val_CER improved from 0.83077 to 0.63846, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 43; loss: 1.7036070823669434; CER: 0.09935897588729858; WER: 0.40918803215026855; val_loss: 13.076189994812012; val_CER: 0.6384615302085876; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 1.7036 - CER: 0.1014 - WER: 0.4153 - val_loss: 13.0762 - val_CER: 0.6385 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 45/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5631 - CER: 0.0811 - WER: 0.3537\n",
            "Epoch 45: val_CER improved from 0.63846 to 0.63462, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 44; loss: 1.5630770921707153; CER: 0.08504272997379303; WER: 0.3611111044883728; val_loss: 14.755290031433105; val_CER: 0.6346153616905212; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 1.5631 - CER: 0.0813 - WER: 0.3542 - val_loss: 14.7553 - val_CER: 0.6346 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 46/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4733 - CER: 0.0812 - WER: 0.3340\n",
            "Epoch 46: val_CER did not improve from 0.63462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 45; loss: 1.473323941230774; CER: 0.08119659870862961; WER: 0.345085471868515; val_loss: 16.243385314941406; val_CER: 0.6865384578704834; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 1.4733 - CER: 0.0812 - WER: 0.3347 - val_loss: 16.2434 - val_CER: 0.6865 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 47/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3851 - CER: 0.0720 - WER: 0.2923\n",
            "Epoch 47: val_CER did not improve from 0.63462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 46; loss: 1.3850525617599487; CER: 0.07649572193622589; WER: 0.3194444477558136; val_loss: 17.57558822631836; val_CER: 0.7653846740722656; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 1.3851 - CER: 0.0723 - WER: 0.2940 - val_loss: 17.5756 - val_CER: 0.7654 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 48/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3360 - CER: 0.0703 - WER: 0.2945\n",
            "Epoch 48: val_CER improved from 0.63462 to 0.28269, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 47; loss: 1.3359936475753784; CER: 0.0724359005689621; WER: 0.31089743971824646; val_loss: 4.758038520812988; val_CER: 0.2826923131942749; val_WER: 0.8269230723381042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 1.3360 - CER: 0.0704 - WER: 0.2955 - val_loss: 4.7580 - val_CER: 0.2827 - val_WER: 0.8269 - lr: 9.0000e-04\n",
            "Epoch 49/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3143 - CER: 0.0631 - WER: 0.2700\n",
            "Epoch 49: val_CER did not improve from 0.28269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 48; loss: 1.3142775297164917; CER: 0.06923076510429382; WER: 0.29914531111717224; val_loss: 5.233255863189697; val_CER: 0.3134615123271942; val_WER: 0.8653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 1.3143 - CER: 0.0635 - WER: 0.2718 - val_loss: 5.2333 - val_CER: 0.3135 - val_WER: 0.8654 - lr: 9.0000e-04\n",
            "Epoch 50/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2216 - CER: 0.0603 - WER: 0.2620\n",
            "Epoch 50: val_CER did not improve from 0.28269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 49; loss: 1.2215579748153687; CER: 0.06474359333515167; WER: 0.2788461446762085; val_loss: 5.020917892456055; val_CER: 0.2826923131942749; val_WER: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 1.2216 - CER: 0.0606 - WER: 0.2631 - val_loss: 5.0209 - val_CER: 0.2827 - val_WER: 0.8750 - lr: 9.0000e-04\n",
            "Epoch 51/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1274 - CER: 0.0586 - WER: 0.2625\n",
            "Epoch 51: val_CER improved from 0.28269 to 0.15000, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 50; loss: 1.1273868083953857; CER: 0.060256410390138626; WER: 0.26923078298568726; val_loss: 2.514333963394165; val_CER: 0.15000000596046448; val_WER: 0.5961538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 1.1274 - CER: 0.0587 - WER: 0.2629 - val_loss: 2.5143 - val_CER: 0.1500 - val_WER: 0.5962 - lr: 9.0000e-04\n",
            "Epoch 52/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0955 - CER: 0.0590 - WER: 0.2596\n",
            "Epoch 52: val_CER did not improve from 0.15000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 51; loss: 1.095484733581543; CER: 0.06111111119389534; WER: 0.2670940160751343; val_loss: 8.156960487365723; val_CER: 0.39615386724472046; val_WER: 0.9230769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 1.0955 - CER: 0.0591 - WER: 0.2601 - val_loss: 8.1570 - val_CER: 0.3962 - val_WER: 0.9231 - lr: 9.0000e-04\n",
            "Epoch 53/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0196 - CER: 0.0522 - WER: 0.2357\n",
            "Epoch 53: val_CER did not improve from 0.15000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 52; loss: 1.0195876359939575; CER: 0.05277778208255768; WER: 0.23397435247898102; val_loss: 3.0000431537628174; val_CER: 0.18269230425357819; val_WER: 0.682692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 1.0196 - CER: 0.0522 - WER: 0.2356 - val_loss: 3.0000 - val_CER: 0.1827 - val_WER: 0.6827 - lr: 9.0000e-04\n",
            "Epoch 54/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9605 - CER: 0.0451 - WER: 0.1948\n",
            "Epoch 54: val_CER did not improve from 0.15000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 53; loss: 0.9605056047439575; CER: 0.05021367967128754; WER: 0.2211538404226303; val_loss: 3.4005627632141113; val_CER: 0.19423078000545502; val_WER: 0.7115384340286255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.9605 - CER: 0.0454 - WER: 0.1964 - val_loss: 3.4006 - val_CER: 0.1942 - val_WER: 0.7115 - lr: 9.0000e-04\n",
            "Epoch 55/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9188 - CER: 0.0491 - WER: 0.2294\n",
            "Epoch 55: val_CER improved from 0.15000 to 0.14423, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 54; loss: 0.9187546968460083; CER: 0.05106838047504425; WER: 0.23076923191547394; val_loss: 2.4711365699768066; val_CER: 0.14423076808452606; val_WER: 0.5480769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 48s 3s/step - loss: 0.9188 - CER: 0.0492 - WER: 0.2295 - val_loss: 2.4711 - val_CER: 0.1442 - val_WER: 0.5481 - lr: 9.0000e-04\n",
            "Epoch 56/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9063 - CER: 0.0468 - WER: 0.2035\n",
            "Epoch 56: val_CER did not improve from 0.14423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 55; loss: 0.9063342809677124; CER: 0.04850427806377411; WER: 0.21260683238506317; val_loss: 3.6957836151123047; val_CER: 0.20192307233810425; val_WER: 0.682692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 0.9063 - CER: 0.0469 - WER: 0.2041 - val_loss: 3.6958 - val_CER: 0.2019 - val_WER: 0.6827 - lr: 9.0000e-04\n",
            "Epoch 57/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8464 - CER: 0.0444 - WER: 0.2084\n",
            "Epoch 57: val_CER improved from 0.14423 to 0.11154, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 56; loss: 0.8463764786720276; CER: 0.045085471123456955; WER: 0.2083333283662796; val_loss: 2.0248324871063232; val_CER: 0.11153846234083176; val_WER: 0.4711538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 0.8464 - CER: 0.0445 - WER: 0.2084 - val_loss: 2.0248 - val_CER: 0.1115 - val_WER: 0.4712 - lr: 9.0000e-04\n",
            "Epoch 58/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7722 - CER: 0.0399 - WER: 0.1886\n",
            "Epoch 58: val_CER improved from 0.11154 to 0.06346, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 57; loss: 0.7722242474555969; CER: 0.0386752113699913; WER: 0.1805555522441864; val_loss: 1.3447237014770508; val_CER: 0.0634615421295166; val_WER: 0.3076923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.7722 - CER: 0.0399 - WER: 0.1881 - val_loss: 1.3447 - val_CER: 0.0635 - val_WER: 0.3077 - lr: 9.0000e-04\n",
            "Epoch 59/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7317 - CER: 0.0423 - WER: 0.1933\n",
            "Epoch 59: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 58; loss: 0.7316760420799255; CER: 0.03995726630091667; WER: 0.18482905626296997; val_loss: 2.2887823581695557; val_CER: 0.126923069357872; val_WER: 0.5192307829856873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 0.7317 - CER: 0.0421 - WER: 0.1928 - val_loss: 2.2888 - val_CER: 0.1269 - val_WER: 0.5192 - lr: 9.0000e-04\n",
            "Epoch 60/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7123 - CER: 0.0404 - WER: 0.1851\n",
            "Epoch 60: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 59; loss: 0.7123139500617981; CER: 0.03782051429152489; WER: 0.17200854420661926; val_loss: 2.64404296875; val_CER: 0.1538461595773697; val_WER: 0.6153846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.7123 - CER: 0.0402 - WER: 0.1843 - val_loss: 2.6440 - val_CER: 0.1538 - val_WER: 0.6154 - lr: 9.0000e-04\n",
            "Epoch 61/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6529 - CER: 0.0404 - WER: 0.1908\n",
            "Epoch 61: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 60; loss: 0.6528772115707397; CER: 0.03611111268401146; WER: 0.17200854420661926; val_loss: 3.0187125205993652; val_CER: 0.18269230425357819; val_WER: 0.682692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.6529 - CER: 0.0401 - WER: 0.1897 - val_loss: 3.0187 - val_CER: 0.1827 - val_WER: 0.6827 - lr: 9.0000e-04\n",
            "Epoch 62/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6037 - CER: 0.0296 - WER: 0.1384\n",
            "Epoch 62: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 61; loss: 0.6037291884422302; CER: 0.029487179592251778; WER: 0.13354700803756714; val_loss: 4.977357387542725; val_CER: 0.30384618043899536; val_WER: 0.8653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 0.6037 - CER: 0.0296 - WER: 0.1381 - val_loss: 4.9774 - val_CER: 0.3038 - val_WER: 0.8654 - lr: 9.0000e-04\n",
            "Epoch 63/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6515 - CER: 0.0346 - WER: 0.1594\n",
            "Epoch 63: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 62; loss: 0.651523232460022; CER: 0.03611110895872116; WER: 0.1677350401878357; val_loss: 4.6210503578186035; val_CER: 0.26346153020858765; val_WER: 0.9134615659713745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.6515 - CER: 0.0347 - WER: 0.1599 - val_loss: 4.6211 - val_CER: 0.2635 - val_WER: 0.9135 - lr: 9.0000e-04\n",
            "Epoch 64/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6692 - CER: 0.0414 - WER: 0.1859\n",
            "Epoch 64: val_CER did not improve from 0.06346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 63; loss: 0.6692413687705994; CER: 0.03910256549715996; WER: 0.17628204822540283; val_loss: 2.324664354324341; val_CER: 0.14038461446762085; val_WER: 0.5961538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.6692 - CER: 0.0412 - WER: 0.1853 - val_loss: 2.3247 - val_CER: 0.1404 - val_WER: 0.5962 - lr: 9.0000e-04\n",
            "Epoch 65/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5602 - CER: 0.0257 - WER: 0.1215\n",
            "Epoch 65: val_CER improved from 0.06346 to 0.05192, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 64; loss: 0.5601702332496643; CER: 0.029700858518481255; WER: 0.1367521435022354; val_loss: 1.2158493995666504; val_CER: 0.051923077553510666; val_WER: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 0.5602 - CER: 0.0259 - WER: 0.1224 - val_loss: 1.2158 - val_CER: 0.0519 - val_WER: 0.2500 - lr: 9.0000e-04\n",
            "Epoch 66/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5495 - CER: 0.0308 - WER: 0.1441\n",
            "Epoch 66: val_CER improved from 0.05192 to 0.05000, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 65; loss: 0.5495352149009705; CER: 0.028205130249261856; WER: 0.13141025602817535; val_loss: 1.307845115661621; val_CER: 0.05000000447034836; val_WER: 0.24038460850715637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.5495 - CER: 0.0306 - WER: 0.1433 - val_loss: 1.3078 - val_CER: 0.0500 - val_WER: 0.2404 - lr: 9.0000e-04\n",
            "Epoch 67/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4963 - CER: 0.0259 - WER: 0.1232\n",
            "Epoch 67: val_CER improved from 0.05000 to 0.04423, saving model to Models/02_captcha_to_text/202404171552/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 66; loss: 0.49626028537750244; CER: 0.025427350774407387; WER: 0.11965811997652054; val_loss: 0.9587940573692322; val_CER: 0.04423076659440994; val_WER: 0.21153846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 47s 3s/step - loss: 0.4963 - CER: 0.0259 - WER: 0.1230 - val_loss: 0.9588 - val_CER: 0.0442 - val_WER: 0.2115 - lr: 9.0000e-04\n",
            "Epoch 68/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4678 - CER: 0.0253 - WER: 0.1206\n",
            "Epoch 68: val_CER did not improve from 0.04423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 67; loss: 0.4678451716899872; CER: 0.02606837823987007; WER: 0.12393162399530411; val_loss: 1.35899817943573; val_CER: 0.05384615808725357; val_WER: 0.26923078298568726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 45s 3s/step - loss: 0.4678 - CER: 0.0253 - WER: 0.1208 - val_loss: 1.3590 - val_CER: 0.0538 - val_WER: 0.2692 - lr: 9.0000e-04\n",
            "Epoch 69/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4665 - CER: 0.0288 - WER: 0.1399\n",
            "Epoch 69: val_CER did not improve from 0.04423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 68; loss: 0.46646228432655334; CER: 0.027350427582859993; WER: 0.13247863948345184; val_loss: 1.0080604553222656; val_CER: 0.04999999701976776; val_WER: 0.24038460850715637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.4665 - CER: 0.0287 - WER: 0.1395 - val_loss: 1.0081 - val_CER: 0.0500 - val_WER: 0.2404 - lr: 9.0000e-04\n",
            "Epoch 70/70\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5082 - CER: 0.0289 - WER: 0.1399\n",
            "Epoch 70: val_CER did not improve from 0.04423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 69; loss: 0.5081627368927002; CER: 0.028418803587555885; WER: 0.1378205120563507; val_loss: 1.5910942554473877; val_CER: 0.07499999552965164; val_WER: 0.3461538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 46s 3s/step - loss: 0.5082 - CER: 0.0288 - WER: 0.1398 - val_loss: 1.5911 - val_CER: 0.0750 - val_WER: 0.3462 - lr: 9.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tf2onnx.tfonnx:Using tensorflow=2.10.1, onnx=1.12.0, tf2onnx=1.14.0/8f8d49\n",
            "INFO:tf2onnx.tfonnx:Using opset <onnx, 15>\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 2 values for constant folding\n",
            "INFO:tf2onnx.tfonnx:folding node using tf type=StridedSlice, name=model/bidirectional/forward_lstm/PartitionedCall/strided_slice\n",
            "INFO:tf2onnx.tfonnx:folding node using tf type=StridedSlice, name=model/bidirectional/backward_lstm/PartitionedCall/strided_slice\n",
            "INFO:tf2onnx.optimizer:Optimizing ONNX model\n",
            "INFO:tf2onnx.optimizer:After optimization: BatchNormalization -18 (18->0), Cast -4 (11->7), Concat -4 (10->6), Const -128 (194->66), Expand -3 (4->1), Gather +2 (2->4), Identity -2 (2->0), Shape -1 (4->3), Slice -1 (5->4), Squeeze -3 (5->2), Transpose -83 (87->4), Unsqueeze -14 (17->3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install text-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCMeUfzhBHaw",
        "outputId": "53709187-41fd-4fb9-9d3b-bc4560cba9ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting text-utils\n",
            "  Downloading text_utils-0.0.5-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from text-utils) (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from text-utils) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from text-utils) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->text-utils) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->text-utils) (1.16.0)\n",
            "Installing collected packages: text-utils\n",
            "Successfully installed text-utils-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeNo1VfpCu2K",
        "outputId": "4223305a-c60c-4275-8a7b-d2467e53559b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifying Results"
      ],
      "metadata": {
        "id": "mlghQnz3G8Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import typing\n",
        "import numpy as np\n",
        "import Levenshtein\n",
        "\n",
        "from mltu.inferenceModel import OnnxInferenceModel\n",
        "\n",
        "class ImageToWordModel(OnnxInferenceModel):\n",
        "    def __init__(self, char_list: typing.Union[str, list], *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.char_list = char_list\n",
        "\n",
        "    @staticmethod\n",
        "    def ctc_decoder(preds, char_list):\n",
        "        decoded_texts = []\n",
        "\n",
        "        for pred in preds:\n",
        "            decoded_text = ''\n",
        "            previous_index = len(char_list)  # Initialize previous_index to an invalid value\n",
        "\n",
        "            for timestep_pred in pred:\n",
        "                max_index = np.argmax(timestep_pred)\n",
        "\n",
        "                # Check if the max_index is valid and not the blank index\n",
        "                if 0 <= max_index < len(char_list) and max_index != len(char_list) - 1:\n",
        "                    # Append the character to the decoded text\n",
        "                    decoded_text += char_list[max_index]\n",
        "\n",
        "                # Update previous_index\n",
        "                previous_index = max_index\n",
        "\n",
        "            decoded_texts.append(decoded_text)\n",
        "\n",
        "        return decoded_texts\n",
        "\n",
        "    @staticmethod\n",
        "    def get_cer(prediction_text, label):\n",
        "       # Ensure both prediction_text and label are strings\n",
        "        if not isinstance(prediction_text, str) or not isinstance(label, str):\n",
        "            raise ValueError(\"Both prediction_text and label must be strings\")\n",
        "\n",
        "        # Initialize variables to store counts of insertions, deletions, and substitutions\n",
        "        insertions = deletions = substitutions = 0\n",
        "\n",
        "        # Lengths of prediction_text and label\n",
        "        len_pred = len(prediction_text)\n",
        "        len_label = len(label)\n",
        "\n",
        "        # Initialize matrices for dynamic programming approach\n",
        "        dp = [[0] * (len_label + 1) for _ in range(len_pred + 1)]\n",
        "\n",
        "        # Initialize first row and column of dp matrix\n",
        "        for i in range(len_pred + 1):\n",
        "            dp[i][0] = i\n",
        "        for j in range(len_label + 1):\n",
        "            dp[0][j] = j\n",
        "\n",
        "        # Calculate edit distance using dynamic programming\n",
        "        for i in range(1, len_pred + 1):\n",
        "            for j in range(1, len_label + 1):\n",
        "                if prediction_text[i - 1] == label[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1]\n",
        "                else:\n",
        "                    dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "\n",
        "        # Edit distance is the last cell in the matrix\n",
        "        edit_distance = dp[len_pred][len_label]\n",
        "\n",
        "        # Calculate CER\n",
        "        cer = edit_distance / len_label\n",
        "\n",
        "        return cer\n",
        "\n",
        "    def predict(self, image: np.ndarray):\n",
        "        image = cv2.resize(image, self.input_shape[:2][::-1])\n",
        "\n",
        "        image_pred = np.expand_dims(image, axis=0).astype(np.float32)\n",
        "\n",
        "        preds = self.model.run(None, {self.input_name: image_pred})[0]\n",
        "\n",
        "        text = self.ctc_decoder(preds, self.char_list)[0]\n",
        "\n",
        "        return text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "    from mltu.configs import BaseModelConfigs\n",
        "\n",
        "    configs = BaseModelConfigs.load(\"/content/Models/02_captcha_to_text/202404171552/configs.yaml\")\n",
        "\n",
        "    model = ImageToWordModel(model_path=configs.model_path, char_list=configs.vocab)\n",
        "\n",
        "    df = pd.read_csv(\"/content/Models/02_captcha_to_text/202404171552/val.csv\").values.tolist()\n",
        "\n",
        "    accum_cer = []\n",
        "    for image_path, label in tqdm(df):\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        prediction_text = model.predict(image)\n",
        "\n",
        "        cer = model.get_cer(prediction_text, label)\n",
        "        print(f\"Image: {image_path}, Label: {label}, Prediction: {prediction_text}, CER: {cer}\")\n",
        "\n",
        "        accum_cer.append(cer)\n",
        "\n",
        "    print(f\"Average CER: {np.average(accum_cer)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTR-oIk6Rtb",
        "outputId": "bc6395da-f43d-4ac6-936a-0493777d3524"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 16/104 [00:00<00:00, 154.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/3ebnn.png, Label: 3ebnn, Prediction: 3ebnn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/wf684.png, Label: wf684, Prediction: wf6844, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6pfy4.png, Label: 6pfy4, Prediction: 6pfy4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n7ff2.png, Label: n7ff2, Prediction: n7ff2, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/478nx.png, Label: 478nx, Prediction: 478nx, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nnfx3.png, Label: nnfx3, Prediction: nnfxx3, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/cnmnn.png, Label: cnmnn, Prediction: nmnnn, CER: 0.4\n",
            "Image: Datasets/captcha_images_v2/ddcne.png, Label: ddcne, Prediction: ddne, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6cm6m.png, Label: 6cm6m, Prediction: 6m6m, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/b28g8.png, Label: b28g8, Prediction: b28g8, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/5n245.png, Label: 5n245, Prediction: 5n245, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/244e2.png, Label: 244e2, Prediction: 244e2, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mgw3n.png, Label: mgw3n, Prediction: mgw3n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ymp7g.png, Label: ymp7g, Prediction: ymp7g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/6pwcn.png, Label: 6pwcn, Prediction: 6pwn, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6bxwg.png, Label: 6bxwg, Prediction: 6bxwg, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/f83pn.png, Label: f83pn, Prediction: f83pn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/c43b4.png, Label: c43b4, Prediction: 43b4, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6mygb.png, Label: 6mygb, Prediction: 6nygb, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/wmpmp.png, Label: wmpmp, Prediction: wmpmp, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/8n34n.png, Label: 8n34n, Prediction: 8n34n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/64b3p.png, Label: 64b3p, Prediction: 64b33p, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/664nf.png, Label: 664nf, Prediction: 664nf, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/g2fnw.png, Label: g2fnw, Prediction: g2fnw, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nwfde.png, Label: nwfde, Prediction: nwfde, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/pyf65.png, Label: pyf65, Prediction: pyf65, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n5cm7.png, Label: n5cm7, Prediction: n5m7, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/m3b5p.png, Label: m3b5p, Prediction: m33b5p, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/pxne8.png, Label: pxne8, Prediction: pxne8, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/g55b4.png, Label: g55b4, Prediction: g55b4, CER: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 47/104 [00:00<00:00, 145.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/2p2y8.png, Label: 2p2y8, Prediction: 2p2yy8, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/gpnxn.png, Label: gpnxn, Prediction: gpnxn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/g8gnd.png, Label: g8gnd, Prediction: g8gnnd, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/mbf58.png, Label: mbf58, Prediction: mbf588, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/4ycex.png, Label: 4ycex, Prediction: 4yex, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/2356g.png, Label: 2356g, Prediction: 2356g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mg5nn.png, Label: mg5nn, Prediction: mg5nn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/4w6mw.png, Label: 4w6mw, Prediction: 4w6mw, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/bgd4m.png, Label: bgd4m, Prediction: bgd4m, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/44fyb.png, Label: 44fyb, Prediction: 44fyb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/24pew.png, Label: 24pew, Prediction: 74pew, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/5bb66.png, Label: 5bb66, Prediction: 5bbb66, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/378e5.png, Label: 378e5, Prediction: 378e5, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/68x48.png, Label: 68x48, Prediction: 68x448, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/e6m6p.png, Label: e6m6p, Prediction: e6m6p, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/m74dm.png, Label: m74dm, Prediction: m74dm, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xdcn4.png, Label: xdcn4, Prediction: xdn4, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/wbncw.png, Label: wbncw, Prediction: wbnw, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/m67b3.png, Label: m67b3, Prediction: m67b3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/x8e8n.png, Label: x8e8n, Prediction: x8e88n, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/n3ffn.png, Label: n3ffn, Prediction: n3f8n, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/cdcb3.png, Label: cdcb3, Prediction: edb3, CER: 0.4\n",
            "Image: Datasets/captcha_images_v2/5fyem.png, Label: 5fyem, Prediction: 5fyem, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/377xx.png, Label: 377xx, Prediction: 377xxx, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/dxwcw.png, Label: dxwcw, Prediction: dxwww, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/3ebpw.png, Label: 3ebpw, Prediction: 3ebpw, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/fncnb.png, Label: fncnb, Prediction: fnnb, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/cd6p4.png, Label: cd6p4, Prediction: d6pp4, CER: 0.4\n",
            "Image: Datasets/captcha_images_v2/pw5nc.png, Label: pw5nc, Prediction: pw5n, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/43mn5.png, Label: 43mn5, Prediction: 43mn55, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/5nnff.png, Label: 5nnff, Prediction: 5nnfff, CER: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 77/104 [00:00<00:00, 145.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/yyn57.png, Label: yyn57, Prediction: yyn57, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/77wp4.png, Label: 77wp4, Prediction: 77wp44, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/n4xx5.png, Label: n4xx5, Prediction: n4xxx5, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/b4y5x.png, Label: b4y5x, Prediction: b4y5xx, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/eng53.png, Label: eng53, Prediction: eng53, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/245y5.png, Label: 245y5, Prediction: 245yy5, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/ef4mn.png, Label: ef4mn, Prediction: ef4nmn, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/d22bd.png, Label: d22bd, Prediction: d22bd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xe6eb.png, Label: xe6eb, Prediction: xe6eb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mc35n.png, Label: mc35n, Prediction: m35n, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/p2dw7.png, Label: p2dw7, Prediction: p2dw7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/8w875.png, Label: 8w875, Prediction: 8w875, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/5325m.png, Label: 5325m, Prediction: 5325g, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6xen4.png, Label: 6xen4, Prediction: 6xenn4, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/e76n4.png, Label: e76n4, Prediction: e76n4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/3bfnd.png, Label: 3bfnd, Prediction: 3bbfd, CER: 0.4\n",
            "Image: Datasets/captcha_images_v2/4dgf7.png, Label: 4dgf7, Prediction: 4dgdf7, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/gy433.png, Label: gy433, Prediction: gy4333, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/efg72.png, Label: efg72, Prediction: efg72, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/dnxdp.png, Label: dnxdp, Prediction: dnxxp, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/ny3nn.png, Label: ny3nn, Prediction: ny3nn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/yf424.png, Label: yf424, Prediction: yf424, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n4cpy.png, Label: n4cpy, Prediction: n4y, CER: 0.4\n",
            "Image: Datasets/captcha_images_v2/832f3.png, Label: 832f3, Prediction: 832f3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nbcgb.png, Label: nbcgb, Prediction: nbgb, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/yemy4.png, Label: yemy4, Prediction: yemyy4, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/76353.png, Label: 76353, Prediction: 76353, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/bxxfc.png, Label: bxxfc, Prediction: bxxf, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/mwdf6.png, Label: mwdf6, Prediction: mwwdf6, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/6ge3p.png, Label: 6ge3p, Prediction: 6ge33p, CER: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:00<00:00, 147.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/c7gb3.png, Label: c7gb3, Prediction: 7gb3, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/e3ndn.png, Label: e3ndn, Prediction: e3ndn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/4w76g.png, Label: 4w76g, Prediction: 4w76gg, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/m23bp.png, Label: m23bp, Prediction: m23bp, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/pybee.png, Label: pybee, Prediction: pybeee, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/d2nbn.png, Label: d2nbn, Prediction: d2nbn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gbxyy.png, Label: gbxyy, Prediction: gbxyyy, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/wb3ed.png, Label: wb3ed, Prediction: wb3ed, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/42dw4.png, Label: 42dw4, Prediction: 42dw4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/5p8fm.png, Label: 5p8fm, Prediction: 3p8fm, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/mfb3x.png, Label: mfb3x, Prediction: mfb3x, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/87nym.png, Label: 87nym, Prediction: 87nym, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ec6pm.png, Label: ec6pm, Prediction: e5pm, CER: 0.4\n",
            "Average CER: 0.11538461538461539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iaSjIanGCCch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}